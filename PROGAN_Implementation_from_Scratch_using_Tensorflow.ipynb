{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJdK0TVJeqrs"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "from numpy import load\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "from skimage.transform import resize\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import AveragePooling2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Layer\n",
        "from keras.layers import Add\n",
        "from keras.constraints import max_norm\n",
        "from keras.initializers import RandomNormal\n",
        "from keras import backend\n",
        "from matplotlib import pyplot\n",
        "\n",
        "class PixelNormalization(Layer):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(PixelNormalization, self).__init__(**kwargs)\n",
        "\n",
        "\tdef call(self, inputs):\n",
        "\t\tvalues = inputs**2.0\n",
        "\t\tmean_values = backend.mean(values, axis=-1, keepdims=True)\n",
        "\t\tmean_values += 1.0e-8\n",
        "\t\tl2 = backend.sqrt(mean_values)\n",
        "\t\tnormalized = inputs / l2\n",
        "\t\treturn normalized\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\treturn input_shape\n",
        "\n",
        "class MinibatchStdev(Layer):\n",
        "\tdef __init__(self, **kwargs):\n",
        "\t\tsuper(MinibatchStdev, self).__init__(**kwargs)\n",
        "\n",
        "\tdef call(self, inputs):\n",
        "\t\tmean = backend.mean(inputs, axis=0, keepdims=True)\n",
        "\t\tsqu_diffs = backend.square(inputs - mean)\n",
        "\t\tmean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n",
        "\t\tmean_sq_diff += 1e-8\n",
        "\t\tstdev = backend.sqrt(mean_sq_diff)\n",
        "\t\tmean_pix = backend.mean(stdev, keepdims=True)\n",
        "\t\tshape = backend.shape(inputs)\n",
        "\t\toutput = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n",
        "\t\tcombined = backend.concatenate([inputs, output], axis=-1)\n",
        "\t\treturn combined\n",
        "\n",
        "\tdef compute_output_shape(self, input_shape):\n",
        "\t\tinput_shape = list(input_shape)\n",
        "\t\tinput_shape[-1] += 1\n",
        "\t\treturn tuple(input_shape)\n",
        "\n",
        "class WeightedSum(Add):\n",
        "\tdef __init__(self, alpha=0.0, **kwargs):\n",
        "\t\tsuper(WeightedSum, self).__init__(**kwargs)\n",
        "\t\tself.alpha = backend.variable(alpha, name='ws_alpha')\n",
        "\n",
        "\tdef _merge_function(self, inputs):\n",
        "\t\tassert (len(inputs) == 2)\n",
        "\t\toutput = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n",
        "\t\treturn output\n",
        "\n",
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn backend.mean(y_true * y_pred)\n",
        "\n",
        "def add_discriminator_block(old_model, n_input_layers=3):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tconst = max_norm(1.0)\n",
        "\tin_shape = list(old_model.input.shape)\n",
        "\tinput_shape = (in_shape[-2].value*2, in_shape[-2].value*2, in_shape[-1].value)\n",
        "\tin_image = Input(shape=input_shape)\n",
        "\td = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = AveragePooling2D()(d)\n",
        "\tblock_new = d\n",
        "\tfor i in range(n_input_layers, len(old_model.layers)):\n",
        "\t\td = old_model.layers[i](d)\n",
        "\tmodel1 = Model(in_image, d)\n",
        "\tmodel1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\tdownsample = AveragePooling2D()(in_image)\n",
        "\tblock_old = old_model.layers[1](downsample)\n",
        "\tblock_old = old_model.layers[2](block_old)\n",
        "\td = WeightedSum()([block_old, block_new])\n",
        "\tfor i in range(n_input_layers, len(old_model.layers)):\n",
        "\t\td = old_model.layers[i](d)\n",
        "\tmodel2 = Model(in_image, d)\n",
        "\tmodel2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\treturn [model1, model2]\n",
        "\n",
        "def define_discriminator(n_blocks, input_shape=(4,4,3)):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tconst = max_norm(1.0)\n",
        "\tmodel_list = list()\n",
        "\tin_image = Input(shape=input_shape)\n",
        "\td = Conv2D(128, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = MinibatchStdev()(d)\n",
        "\td = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(128, (4,4), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Flatten()(d)\n",
        "\tout_class = Dense(1)(d)\n",
        "\tmodel = Model(in_image, out_class)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\tmodel_list.append([model, model])\n",
        "\tfor i in range(1, n_blocks):\n",
        "\t\told_model = model_list[i - 1][0]\n",
        "\t\tmodels = add_discriminator_block(old_model)\n",
        "\t\tmodel_list.append(models)\n",
        "\treturn model_list\n",
        "\n",
        "def add_generator_block(old_model):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tconst = max_norm(1.0)\n",
        "\tblock_end = old_model.layers[-2].output\n",
        "\tupsampling = UpSampling2D()(block_end)\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(upsampling)\n",
        "\tg = PixelNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "\tg = PixelNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\tout_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "\tmodel1 = Model(old_model.input, out_image)\n",
        "\tout_old = old_model.layers[-1]\n",
        "\tout_image2 = out_old(upsampling)\n",
        "\tmerged = WeightedSum()([out_image2, out_image])\n",
        "\tmodel2 = Model(old_model.input, merged)\n",
        "\treturn [model1, model2]\n",
        "\n",
        "def define_generator(latent_dim, n_blocks, in_dim=4):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tconst = max_norm(1.0)\n",
        "\tmodel_list = list()\n",
        "\tin_latent = Input(shape=(latent_dim,))\n",
        "\tg  = Dense(128 * in_dim * in_dim, kernel_initializer=init, kernel_constraint=const)(in_latent)\n",
        "\tg = Reshape((in_dim, in_dim, 128))(g)\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "\tg = PixelNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\tg = Conv2D(128, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "\tg = PixelNormalization()(g)\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\tout_image = Conv2D(3, (1,1), padding='same', kernel_initializer=init, kernel_constraint=const)(g)\n",
        "\tmodel = Model(in_latent, out_image)\n",
        "\tmodel_list.append([model, model])\n",
        "\tfor i in range(1, n_blocks):\n",
        "\t\told_model = model_list[i - 1][0]\n",
        "\t\tmodels = add_generator_block(old_model)\n",
        "\t\tmodel_list.append(models)\n",
        "\treturn model_list\n",
        "\n",
        "def define_composite(discriminators, generators):\n",
        "\tmodel_list = list()\n",
        "\tfor i in range(len(discriminators)):\n",
        "\t\tg_models, d_models = generators[i], discriminators[i]\n",
        "\t\td_models[0].trainable = False\n",
        "\t\tmodel1 = Sequential()\n",
        "\t\tmodel1.add(g_models[0])\n",
        "\t\tmodel1.add(d_models[0])\n",
        "\t\tmodel1.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t\td_models[1].trainable = False\n",
        "\t\tmodel2 = Sequential()\n",
        "\t\tmodel2.add(g_models[1])\n",
        "\t\tmodel2.add(d_models[1])\n",
        "\t\tmodel2.compile(loss=wasserstein_loss, optimizer=Adam(lr=0.001, beta_1=0, beta_2=0.99, epsilon=10e-8))\n",
        "\t\tmodel_list.append([model1, model2])\n",
        "\treturn model_list\n",
        "\n",
        "def load_real_samples(filename):\n",
        "\tdata = load(filename)\n",
        "\tX = data['arr_0']\n",
        "\tX = X.astype('float32')\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\tX = dataset[ix]\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\tX = generator.predict(x_input)\n",
        "\ty = -ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "def update_fadein(models, step, n_steps):\n",
        "\t# calculate current alpha (linear from 0 to 1)\n",
        "\talpha = step / float(n_steps - 1)\n",
        "\t# update the alpha for each model\n",
        "\tfor model in models:\n",
        "\t\tfor layer in model.layers:\n",
        "\t\t\tif isinstance(layer, WeightedSum):\n",
        "\t\t\t\tbackend.set_value(layer.alpha, alpha)\n",
        "\n",
        "# train a generator and discriminator\n",
        "def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update alpha for all WeightedSum layers when fading in new blocks\n",
        "\t\tif fadein:\n",
        "\t\t\tupdate_fadein([g_model, d_model, gan_model], i, n_steps)\n",
        "\t\t# prepare real and fake samples\n",
        "\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator model\n",
        "\t\td_loss1 = d_model.train_on_batch(X_real, y_real)\n",
        "\t\td_loss2 = d_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tz_input = generate_latent_points(latent_dim, n_batch)\n",
        "\t\ty_real2 = ones((n_batch, 1))\n",
        "\t\tg_loss = gan_model.train_on_batch(z_input, y_real2)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, d1=%.3f, d2=%.3f g=%.3f' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "\n",
        "# scale images to preferred size\n",
        "def scale_dataset(images, new_shape):\n",
        "\timages_list = list()\n",
        "\tfor image in images:\n",
        "\t\t# resize with nearest neighbor interpolation\n",
        "\t\tnew_image = resize(image, new_shape, 0)\n",
        "\t\t# store\n",
        "\t\timages_list.append(new_image)\n",
        "\treturn asarray(images_list)\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(status, g_model, latent_dim, n_samples=25):\n",
        "\t# devise name\n",
        "\tgen_shape = g_model.output_shape\n",
        "\tname = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n",
        "\t# generate images\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# normalize pixel values to the range [0,1]\n",
        "\tX = (X - X.min()) / (X.max() - X.min())\n",
        "\t# plot real images\n",
        "\tsquare = int(sqrt(n_samples))\n",
        "\tfor i in range(n_samples):\n",
        "\t\tpyplot.subplot(square, square, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X[i])\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'plot_%s.png' % (name)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%s.h5' % (name)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# train the generator and discriminator\n",
        "def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n",
        "\t# fit the baseline model\n",
        "\tg_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n",
        "\t# scale dataset to appropriate size\n",
        "\tgen_shape = g_normal.output_shape\n",
        "\tscaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "\tprint('Scaled Data', scaled_data.shape)\n",
        "\t# train normal or straight-through models\n",
        "\ttrain_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n",
        "\tsummarize_performance('tuned', g_normal, latent_dim)\n",
        "\t# process each level of growth\n",
        "\tfor i in range(1, len(g_models)):\n",
        "\t\t# retrieve models for this level of growth\n",
        "\t\t[g_normal, g_fadein] = g_models[i]\n",
        "\t\t[d_normal, d_fadein] = d_models[i]\n",
        "\t\t[gan_normal, gan_fadein] = gan_models[i]\n",
        "\t\t# scale dataset to appropriate size\n",
        "\t\tgen_shape = g_normal.output_shape\n",
        "\t\tscaled_data = scale_dataset(dataset, gen_shape[1:])\n",
        "\t\tprint('Scaled Data', scaled_data.shape)\n",
        "\t\t# train fade-in models for next level of growth\n",
        "\t\ttrain_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n",
        "\t\tsummarize_performance('faded', g_fadein, latent_dim)\n",
        "\t\t# train normal or straight-through models\n",
        "\t\ttrain_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n",
        "\t\tsummarize_performance('tuned', g_normal, latent_dim)\n",
        "\n",
        "# number of growth phases, e.g. 6 == [4, 8, 16, 32, 64, 128]\n",
        "n_blocks = 6\n",
        "# size of the latent space\n",
        "latent_dim = 100\n",
        "# define models\n",
        "d_models = define_discriminator(n_blocks)\n",
        "# define models\n",
        "g_models = define_generator(latent_dim, n_blocks)\n",
        "# define composite models\n",
        "gan_models = define_composite(d_models, g_models)\n",
        "# load image data\n",
        "dataset = load_real_samples('img_align_celeba_128.npz')\n",
        "print('Loaded', dataset.shape)\n",
        "# train model\n",
        "n_batch = [16, 16, 16, 8, 4, 4]\n",
        "# 10 epochs == 500K images per training phase\n",
        "n_epochs = [5, 8, 8, 10, 10, 10]\n",
        "train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)"
      ]
    }
  ]
}